import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import joblib
from sklearn.preprocessing import LabelEncoder
from utils.model_utils import load_model
from utils.recommender import generate_recommendations, generate_student_report, create_csv_report
from utils.clustering import get_cluster_profiles

# Ajout d'imports pour les r√®gles d'association
try:
    from mlxtend.frequent_patterns import apriori, association_rules
    from mlxtend.preprocessing import TransactionEncoder
except ImportError:
    st.warning("mlxtend n'est pas install√©. Installez-le avec: pip install mlxtend")
    apriori = None
    association_rules = None

def interpret_rule(antecedents, consequents):
    """
    Interpr√®te une r√®gle d'association en langage naturel
    """
    # Dictionnaire de traduction des termes techniques
    translations = {
        'Excellentes_Notes': 'avoir d\'excellentes notes',
        'Notes_Faibles': 'avoir des notes faibles',
        'Fort_Absent√©isme': '√™tre tr√®s absent',
        'Faible_Absent√©isme': '√™tre assidu',
        'Tr√®s_Satisfait': '√™tre tr√®s satisfait',
        'Peu_Satisfait': '√™tre peu satisfait',
        'Utilise_Beaucoup_Moodle': 'utiliser beaucoup Moodle',
        'Utilise_Peu_Moodle': 'utiliser peu Moodle',
        'Beaucoup_Devoirs_Rendus': 'rendre beaucoup de devoirs',
        'Peu_Devoirs_Rendus': 'rendre peu de devoirs',
        'Tr√®s_Actif_Forum': '√™tre tr√®s actif sur le forum',
        'Peu_Actif_Forum': '√™tre peu actif sur le forum',
        'Risque_Abandon': 'risquer d\'abandonner',
        '√âtudiant_Persistant': 'persister dans ses √©tudes',
        '√âtudiant_Masculin': '√™tre un √©tudiant masculin',
        '√âtudiante_F√©minine': '√™tre une √©tudiante f√©minine',
        'Parents_√âducation_Sup√©rieure': 'avoir des parents avec √©ducation sup√©rieure',
        'Parents_Sans_√âducation': 'avoir des parents sans √©ducation formelle',
        'R√©gion_Lome': 'venir de Lom√©',
        'R√©gion_Notse': 'venir de Nots√©',
        'R√©gion_Tsevie': 'venir de Ts√©vi√©'
    }
    
    # Traduction des ant√©c√©dents
    ant_translated = []
    for ant in antecedents:
        if ant in translations:
            ant_translated.append(translations[ant])
        else:
            ant_translated.append(ant.replace('_', ' ').lower())
    
    # Traduction des cons√©quents
    cons_translated = []
    for cons in consequents:
        if cons in translations:
            cons_translated.append(translations[cons])
        else:
            cons_translated.append(cons.replace('_', ' ').lower())
    
    # Construction de la phrase
    if len(ant_translated) == 1:
        condition = ant_translated[0]
    elif len(ant_translated) == 2:
        condition = f"{ant_translated[0]} ET {ant_translated[1]}"
    else:
        condition = f"{', '.join(ant_translated[:-1])} ET {ant_translated[-1]}"
    
    if len(cons_translated) == 1:
        result = cons_translated[0]
    else:
        result = f"{', '.join(cons_translated[:-1])} ET {cons_translated[-1]}"
    
    return f"Les √©tudiants qui tendent √† {condition} ont tendance √† {result}"

# üìå Fonction utilitaire pour encodage s√©curis√©
def safe_label_encode(le, values):
    """Encodeur qui g√®re les labels inconnus"""
    values = values.fillna('UNKNOWN').astype(str)
    unseen = set(values.unique()) - set(le.classes_)
    if unseen:
        le.classes_ = np.concatenate([le.classes_, list(unseen)])
    return le.transform(values)

# Configuration de la page
st.set_page_config(
    page_title="Pr√©vention Abandon Scolaire",
    page_icon="üéì",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√©
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
    }
    .cluster-card {
        border: 2px solid #e0e0e0;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    .rule-card {
        background: #f8f9fa;
        border-left: 4px solid #007bff;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 5px;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_data():
    try:
        df = pd.read_csv('data/student_data.csv')
        df_clustered = pd.read_csv('data/student_data_clustered.csv')
        return df, df_clustered
    except FileNotFoundError:
        st.error("Fichiers de donn√©es non trouv√©s. Veuillez ex√©cuter orchestration.py d'abord.")
        return None, None

@st.cache_resource
def load_models():
    try:
        model_data = load_model('models/model.pkl')
        clustering_data = joblib.load('models/clustering_model.pkl')
        return model_data, clustering_data
    except FileNotFoundError:
        st.error("Mod√®les non trouv√©s. Veuillez ex√©cuter orchestration.py d'abord.")
        return None, None

def generate_association_rules_from_data(df):
    """
    G√©n√®re les r√®gles d'association √† partir des donn√©es avec des labels compr√©hensibles
    """
    if apriori is None or association_rules is None:
        return pd.DataFrame()
    
    try:
        # Cr√©ation des variables binaires avec des noms plus explicites
        df_binary = pd.DataFrame()
        
        # Conversion des variables continues en cat√©gories compr√©hensibles
        df_binary['Excellentes_Notes'] = (df['average_grade'] >= df['average_grade'].quantile(0.75)).astype(int)
        df_binary['Notes_Faibles'] = (df['average_grade'] <= df['average_grade'].quantile(0.25)).astype(int)
        df_binary['Fort_Absent√©isme'] = (df['absenteeism_rate'] >= df['absenteeism_rate'].quantile(0.75)).astype(int)
        df_binary['Faible_Absent√©isme'] = (df['absenteeism_rate'] <= df['absenteeism_rate'].quantile(0.25)).astype(int)
        df_binary['Tr√®s_Satisfait'] = (df['satisfaction_score'] >= df['satisfaction_score'].quantile(0.75)).astype(int)
        df_binary['Peu_Satisfait'] = (df['satisfaction_score'] <= df['satisfaction_score'].quantile(0.25)).astype(int)
        df_binary['Utilise_Beaucoup_Moodle'] = (df['moodle_hours'] >= df['moodle_hours'].quantile(0.75)).astype(int)
        df_binary['Utilise_Peu_Moodle'] = (df['moodle_hours'] <= df['moodle_hours'].quantile(0.25)).astype(int)
        df_binary['Beaucoup_Devoirs_Rendus'] = (df['assignments_submitted'] >= df['assignments_submitted'].quantile(0.75)).astype(int)
        df_binary['Peu_Devoirs_Rendus'] = (df['assignments_submitted'] <= df['assignments_submitted'].quantile(0.25)).astype(int)
        df_binary['Tr√®s_Actif_Forum'] = (df['forum_posts'] >= df['forum_posts'].quantile(0.75)).astype(int)
        df_binary['Peu_Actif_Forum'] = (df['forum_posts'] <= df['forum_posts'].quantile(0.25)).astype(int)
        df_binary['Risque_Abandon'] = (df['dropout'] == 'Yes').astype(int)
        df_binary['√âtudiant_Persistant'] = (df['dropout'] == 'No').astype(int)
        
        # Variables cat√©gorielles avec noms explicites
        if 'gender' in df.columns:
            df_binary['√âtudiant_Masculin'] = (df['gender'] == 'Male').astype(int)
            df_binary['√âtudiante_F√©minine'] = (df['gender'] == 'Female').astype(int)
        
        if 'region' in df.columns:
            for region in df['region'].unique():
                df_binary[f'R√©gion_{region}'] = (df['region'] == region).astype(int)
        
        if 'parent_education' in df.columns:
            df_binary['Parents_√âducation_Sup√©rieure'] = (df['parent_education'] == 'Higher').astype(int)
            df_binary['Parents_Sans_√âducation'] = (df['parent_education'] == 'None').astype(int)
        
        # G√©n√©ration des r√®gles d'association
        frequent_itemsets = apriori(df_binary, min_support=0.05, use_colnames=True)
        
        if len(frequent_itemsets) > 0:
            rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.4)
            return rules
        else:
            return pd.DataFrame()
            
    except Exception as e:
        st.error(f"Erreur lors de la g√©n√©ration des r√®gles d'association: {e}")
        return pd.DataFrame()

def show_exploratory_analysis(df, df_clustered):
    st.header("üìä Analyse Exploratoire des Donn√©es")

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <h3>{len(df)}</h3>
            <p>Total √âtudiants</p>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        dropout_rate = (df['dropout'] == 'Yes').mean()
        st.markdown(f"""
        <div class="metric-card">
            <h3>{dropout_rate:.1%}</h3>
            <p>Taux d'Abandon</p>
        </div>
        """, unsafe_allow_html=True)

    with col3:
        avg_grade = df['average_grade'].mean()
        st.markdown(f"""
        <div class="metric-card">
            <h3>{avg_grade:.1f}</h3>
            <p>Note Moyenne</p>
        </div>
        """, unsafe_allow_html=True)

    with col4:
        avg_satisfaction = df['satisfaction_score'].mean()
        st.markdown(f"""
        <div class="metric-card">
            <h3>{avg_satisfaction:.1f}</h3>
            <p>Satisfaction Moyenne</p>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("---")

    # üéØ Section des histogrammes
    st.subheader("üìà Distributions des Variables")
    
    # Premi√®re ligne d'histogrammes
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("Distribution des Notes par Statut")
        fig = px.box(df, x='dropout', y='average_grade', color='dropout', 
                     title="Notes vs Abandon", color_discrete_map={'Yes': '#ff4444', 'No': '#32CD32'})
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.subheader("Distribution des √Çges")
        fig = px.histogram(df, x='age', color='dropout', barmode='group',
                          title="R√©partition des √Çges par Statut",
                          color_discrete_map={'Yes': '#ff4444', 'No': '#32CD32'})
        st.plotly_chart(fig, use_container_width=True)

    # Deuxi√®me ligne d'histogrammes
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("Taux d'Absent√©isme")
        fig = px.histogram(df, x='absenteeism_rate', color='dropout', barmode='group',
                          title="Distribution du Taux d'Absent√©isme",
                          color_discrete_map={'Yes': '#ff4444', 'No': '#32CD32'})
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.subheader("Devoirs Rendus")
        fig = px.histogram(df, x='assignments_submitted', color='dropout', barmode='group',
                          title="Distribution des Devoirs Rendus (%)",
                          color_discrete_map={'Yes': '#ff4444', 'No': '#32CD32'})
        st.plotly_chart(fig, use_container_width=True)

    # Troisi√®me ligne d'histogrammes
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("Utilisation de Moodle")
        fig = px.histogram(df, x='moodle_hours', color='dropout', barmode='group',
                          title="Heures d'Utilisation de Moodle",
                          color_discrete_map={'Yes': '#ff4444', 'No': '#32CD32'})
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.subheader("Score de Satisfaction")
        fig = px.histogram(df, x='satisfaction_score', color='dropout', barmode='group',
                          title="Distribution du Score de Satisfaction",
                          color_discrete_map={'Yes': '#ff4444', 'No': '#32CD32'})
        st.plotly_chart(fig, use_container_width=True)

    # üìä Variables cat√©gorielles
    st.subheader("üîç Analyse des Variables Cat√©gorielles")
    
    col1, col2 = st.columns(2)
    with col1:
        if 'gender' in df.columns:
            st.subheader("R√©partition par Genre")
            gender_dropout = df.groupby(['gender', 'dropout']).size().reset_index(name='count')
            fig = px.bar(gender_dropout, x='gender', y='count', color='dropout',
                        title="Abandon par Genre", barmode='group',
                        color_discrete_map={'Yes': '#ff4444', 'No': '#32CD32'})
            st.plotly_chart(fig, use_container_width=True)

    with col2:
        if 'region' in df.columns:
            st.subheader("R√©partition par R√©gion")
            region_dropout = df.groupby(['region', 'dropout']).size().reset_index(name='count')
            fig = px.bar(region_dropout, x='region', y='count', color='dropout',
                        title="Abandon par R√©gion", barmode='group',
                        color_discrete_map={'Yes': '#ff4444', 'No': '#32CD32'})
            st.plotly_chart(fig, use_container_width=True)

    # üéì √âducation des parents
    if 'parent_education' in df.columns:
        st.subheader("Impact de l'√âducation des Parents")
        parent_ed_dropout = df.groupby(['parent_education', 'dropout']).size().reset_index(name='count')
        fig = px.bar(parent_ed_dropout, x='parent_education', y='count', color='dropout',
                    title="Abandon selon l'√âducation des Parents", barmode='group',
                    color_discrete_map={'Yes': '#ff4444', 'No': '#32CD32'})
        st.plotly_chart(fig, use_container_width=True)

    # üìà Analyse des relations
    st.subheader("üîó Relations entre Variables")
    
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("Absent√©isme vs Notes")
        fig = px.scatter(df, x='absenteeism_rate', y='average_grade',
                         color='dropout', title="Relation Absent√©isme-Notes",
                         color_discrete_map={'Yes': '#ff4444', 'No': '#32CD32'})
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.subheader("Satisfaction vs Notes")
        fig = px.scatter(df, x='satisfaction_score', y='average_grade',
                         color='dropout', title="Relation Satisfaction-Notes",
                         color_discrete_map={'Yes': '#ff4444', 'No': '#32CD32'})
        st.plotly_chart(fig, use_container_width=True)

    # üìä Matrice de corr√©lation
    st.subheader("üîç Matrice de Corr√©lation")
    numeric_cols = ['age', 'average_grade', 'absenteeism_rate', 'assignments_submitted',
                    'moodle_hours', 'forum_posts', 'satisfaction_score']
    corr_matrix = df[numeric_cols].corr()
    fig = px.imshow(corr_matrix, text_auto=True, aspect="auto", 
                    title="Corr√©lations entre Variables",
                    color_continuous_scale='RdBu_r')
    st.plotly_chart(fig, use_container_width=True)

    # üìà Statistiques descriptives
    st.subheader("üìã Statistiques Descriptives")
    
    col1, col2 = st.columns(2)
    with col1:
        st.write("**√âtudiants √† Risque d'Abandon**")
        dropout_stats = df[df['dropout'] == 'Yes'][numeric_cols].describe()
        st.dataframe(dropout_stats.round(2))
    
    with col2:
        st.write("**√âtudiants Persistants**")
        persistent_stats = df[df['dropout'] == 'No'][numeric_cols].describe()
        st.dataframe(persistent_stats.round(2))

def show_clustering_analysis(df_clustered, clustering_data):
    st.header("üéØ Analyse des Profils d'√âtudiants")
    cluster_analysis = clustering_data['cluster_analysis']

    st.subheader("Vue d'ensemble des Clusters")
    cluster_summary = []
    for cluster_name, analysis in cluster_analysis.items():
        cluster_summary.append({
            'Cluster': cluster_name,
            'Taille': analysis['size'],
            'Taux d\'abandon': f"{analysis['dropout_rate']:.1%}",
            'Note moyenne': f"{analysis['avg_grade']:.1f}",
            'Absent√©isme': f"{analysis['avg_absenteeism']:.1f}%",
            'Satisfaction': f"{analysis['avg_satisfaction']:.1f}"
        })

    summary_df = pd.DataFrame(cluster_summary)
    st.dataframe(summary_df, use_container_width=True)

    col1, col2 = st.columns(2)
    with col1:
        st.subheader("Distribution des Clusters")
        cluster_counts = df_clustered['cluster'].value_counts().sort_index()
        fig = px.pie(values=cluster_counts.values, 
                     names=[f'Cluster {i}' for i in cluster_counts.index],
                     title="R√©partition des √âtudiants par Cluster")
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.subheader("Taux d'Abandon par Cluster")
        dropout_by_cluster = df_clustered.groupby('cluster')['dropout'].apply(
            lambda x: (x == 'Yes').mean())
        fig = px.bar(x=dropout_by_cluster.index, y=dropout_by_cluster.values,
                     title="Taux d'Abandon par Cluster",
                     labels={'x': 'Cluster', 'y': 'Taux d\'abandon'})
        st.plotly_chart(fig, use_container_width=True)

    st.subheader("Profils D√©taill√©s des Clusters")
    profiles = get_cluster_profiles()
    for i in range(4):
        if i in profiles:
            with st.expander(f"üìã {profiles[i]['name']} (Cluster {i})"):
                st.write(f"**Description:** {profiles[i]['description']}")
                st.write("**Recommandations :**")
                for rec in profiles[i]['recommendations']:
                    st.write(f"‚Ä¢ {rec}")

def show_prediction_interface(model_data, clustering_data):
    st.header("üîÆ Simulation de Pr√©diction Individuelle")
    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("Informations de l'√âtudiant")
        age = st.slider("√Çge", 18, 40, 25)
        gender = st.selectbox("Genre", ["Male", "Female"])
        region = st.selectbox("R√©gion", ["Lome", "Notse", "Tsevie","Kpalime", "Sokode", "Dapaong", "Atakpame", "Kara"])
        parent_education = st.selectbox("√âducation des Parents", ["None", "Primary", "Secondary", "Higher"])
        average_grade = st.slider("Note Moyenne", 0.0, 20.0, 12.0, 0.1)
        absenteeism_rate = st.slider("Taux d'Absent√©isme (%)", 0.0, 50.0, 15.0, 0.1)
        assignments_submitted = st.slider("Devoirs Rendus (%)", 0.0, 100.0, 80.0, 0.1)
        moodle_hours = st.slider("Heures sur Moodle", 0.0, 50.0, 10.0, 0.1)
        forum_posts = st.slider("Posts Forum", 0, 20, 3)
        satisfaction_score = st.slider("Score de Satisfaction", 1.0, 10.0, 7.0, 0.1)

    with col2:
        st.subheader("R√©sultats de la Pr√©diction")

        if st.button("üöÄ Pr√©dire le Risque", type="primary"):
            student_data = {
                'age': age,
                'gender': gender,
                'region': region,
                'parent_education': parent_education,
                'average_grade': average_grade,
                'absenteeism_rate': absenteeism_rate,
                'assignments_submitted': assignments_submitted,
                'moodle_hours': moodle_hours,
                'forum_posts': forum_posts,
                'satisfaction_score': satisfaction_score
            }

            model = model_data['model']
            scaler = model_data['scaler']
            label_encoders = model_data['label_encoders']

            # Cr√©er un DataFrame temporaire avec les bonnes colonnes
            temp_df = pd.DataFrame([student_data])

            # Encoder les variables cat√©gorielles
            for col, le in label_encoders.items():
                if col in temp_df.columns and col != 'dropout':
                    temp_df[col + '_encoded'] = safe_label_encode(le, temp_df[col])

            # Pr√©parer les features avec les bons noms de colonnes
            feature_cols = ['age', 'gender_encoded', 'region_encoded', 'parent_education_encoded',
                            'average_grade', 'absenteeism_rate', 'assignments_submitted',
                            'moodle_hours', 'forum_posts', 'satisfaction_score']
            
            # CORRECTION : Cr√©er un DataFrame avec les noms de colonnes pour √©viter l'erreur
            X_pred = temp_df[feature_cols].copy()
            X_pred_scaled = scaler.transform(X_pred)
            
            # Cr√©er un DataFrame avec les m√™mes noms de colonnes pour la pr√©diction
            X_pred_scaled_df = pd.DataFrame(X_pred_scaled, columns=feature_cols)

            # Pr√©dictions avec les DataFrames ayant les bons noms de colonnes
            try:
                dropout_probability = model.predict_proba(X_pred_scaled_df)[0][1]
                prediction = model.predict(X_pred_scaled_df)[0]
            except Exception as e:
                st.error(f"Erreur lors de la pr√©diction du mod√®le principal: {e}")
                # Fallback avec array numpy
                dropout_probability = model.predict_proba(X_pred_scaled)[0][1]
                prediction = model.predict(X_pred_scaled)[0]

            # Pr√©diction du cluster
            kmeans_model = clustering_data['kmeans_model']
            try:
                cluster = kmeans_model.predict(X_pred_scaled_df)[0]
            except Exception as e:
                st.warning(f"Utilisation de l'array numpy pour le clustering: {e}")
                cluster = kmeans_model.predict(X_pred_scaled)[0]

            risk_level = "üî¥ √âLEV√â" if dropout_probability > 0.7 else "üü° MOD√âR√â" if dropout_probability > 0.5 else "üü¢ FAIBLE"

            st.markdown(f"""
            ### üìä R√©sultats de l'Analyse
            **Probabilit√© d'abandon:** {dropout_probability:.1%}  
            **Niveau de risque:** {risk_level}  
            **Cluster identifi√©:** Cluster {cluster}
            """)

            recommendations = generate_recommendations(student_data, cluster, dropout_probability)

            st.markdown("### üí° Recommandations Personnalis√©es")
            for i, rec in enumerate(recommendations, 1):
                st.write(f"{i}. {rec}")

            st.markdown("### üì• T√©l√©charger le Rapport")
            
            # G√©n√©rer automatiquement les rapports apr√®s la pr√©diction
            try:
                # G√©n√©ration du PDF
                pdf_buffer = generate_student_report(student_data, cluster, dropout_probability, recommendations)
                
                # G√©n√©ration du CSV
                csv_df = create_csv_report(student_data, cluster, dropout_probability, recommendations)
                csv_string = csv_df.to_csv(index=False)
                
                col_pdf, col_csv = st.columns(2)
                
                with col_pdf:
                    st.download_button(
                        label="üìÑ T√©l√©charger le rapport PDF",
                        data=pdf_buffer.getvalue(),
                        file_name=f"rapport_etudiant_{age}ans.pdf",
                        mime="application/pdf",
                        key="download_pdf"
                    )

                with col_csv:
                    st.download_button(
                        label="üìä T√©l√©charger le rapport CSV",
                        data=csv_string,
                        file_name=f"rapport_etudiant_{age}ans.csv",
                        mime="text/csv",
                        key="download_csv"
                    )
                    
                st.success("‚úÖ Rapports g√©n√©r√©s avec succ√®s! Vous pouvez maintenant les t√©l√©charger.")
                
            except Exception as e:
                st.error(f"‚ùå Erreur lors de la g√©n√©ration des rapports: {e}")
                st.info("üí° V√©rifiez que les fonctions `generate_student_report` et `create_csv_report` sont correctement impl√©ment√©es dans le module `utils.recommender`.")

def show_association_rules(clustering_data, df=None):
    st.header("üîó R√®gles d'Association")
    
    # Debug: Afficher les cl√©s disponibles dans clustering_data
    #st.subheader("üîç Diagnostic des Donn√©es")
    #with st.expander("Voir les cl√©s disponibles dans clustering_data"):
     #   st.write("Cl√©s disponibles:", list(clustering_data.keys()))
    
    # Tentative de r√©cup√©ration des r√®gles depuis le mod√®le sauvegard√©
    rules = clustering_data.get('association_rules', pd.DataFrame())
    
    # Si pas de r√®gles sauvegard√©es, les g√©n√©rer √† partir des donn√©es
    if rules.empty and df is not None:
        st.info("üîÑ G√©n√©ration des r√®gles d'association √† partir des donn√©es...")
        rules = generate_association_rules_from_data(df)
    
    if not rules.empty:
        st.subheader("üìã R√®gles D√©couvertes")
        
        # Filtres pour les r√®gles
        col1, col2, col3 = st.columns(3)
        with col1:
            min_confidence = st.slider("Confiance minimale", 0.0, 1.0, 0.5, 0.05)
        with col2:
            min_support = st.slider("Support minimal", 0.0, 1.0, 0.1, 0.05)
        with col3:
            min_lift = st.slider("Lift minimal", 0.0, 5.0, 1.0, 0.1)
        
        # Filtrer les r√®gles
        filtered_rules = rules[
            (rules['confidence'] >= min_confidence) & 
            (rules['support'] >= min_support) & 
            (rules['lift'] >= min_lift)
        ].head(20)
        
        if not filtered_rules.empty:
            st.success(f"üéØ {len(filtered_rules)} r√®gles trouv√©es avec les crit√®res s√©lectionn√©s")
            
            # Interpr√©tation des r√®gles en langage naturel
            st.subheader("üí° Insights D√©couverts")
            
            # Top 5 des r√®gles les plus importantes
            top_rules = filtered_rules.nlargest(5, 'confidence')
            
            for idx, rule in top_rules.iterrows():
                try:
                    # Gestion des ant√©c√©dents et cons√©quents
                    if hasattr(rule['antecedents'], '__iter__') and not isinstance(rule['antecedents'], str):
                        antecedents = list(rule['antecedents'])
                    else:
                        antecedents = [str(rule['antecedents'])]
                    
                    if hasattr(rule['consequents'], '__iter__') and not isinstance(rule['consequents'], str):
                        consequents = list(rule['consequents'])
                    else:
                        consequents = [str(rule['consequents'])]
                    
                    # Interpr√©tation en langage naturel
                    interpretation = interpret_rule(antecedents, consequents)
                    
                    # D√©terminer la couleur selon la confiance
                    if rule['confidence'] >= 0.8:
                        icon = "üî¥"
                        level = "CRITIQUE"
                        border_color = "#dc3545"
                    elif rule['confidence'] >= 0.6:
                        icon = "üü°"
                        level = "IMPORTANT"
                        border_color = "#ffc107"
                    else:
                        icon = "üü¢"
                        level = "NOTABLE"
                        border_color = "#28a745"
                    
                    st.markdown(f"""
                    <div style="border-left: 4px solid {border_color}; background: #f8f9fa; padding: 1.5rem; margin: 1rem 0; border-radius: 5px;">
                        <h4>{icon} Insight {level}</h4>
                        <p style="font-size: 1.1em; color: #333;"><strong>{interpretation}</strong></p>
                        <div style="display: flex; gap: 20px; margin-top: 15px; font-size: 0.9em;">
                            <span style="background: #e9ecef; padding: 5px 10px; border-radius: 15px;">
                                <strong>Fiabilit√©:</strong> {rule['confidence']:.1%}
                            </span>
                            <span style="background: #e9ecef; padding: 5px 10px; border-radius: 15px;">
                                <strong>Fr√©quence:</strong> {rule['support']:.1%}
                            </span>
                            <span style="background: #e9ecef; padding: 5px 10px; border-radius: 15px;">
                                <strong>Force:</strong> {rule['lift']:.1f}x
                            </span>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                    
                except Exception as e:
                    st.error(f"Erreur lors de l'interpr√©tation de la r√®gle {idx}: {e}")
                    continue
            
            # Graphique des r√®gles
            st.subheader("üìä Visualisation des R√®gles")
            
            # Scatter plot Confiance vs Support
            fig = px.scatter(
                filtered_rules, 
                x='support', 
                y='confidence',
                size='lift',
                color='lift',
                title="R√®gles d'Association: Confiance vs Support",
                labels={'support': 'Support', 'confidence': 'Confiance', 'lift': 'Lift'},
                hover_data=['lift']
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Tableau des r√®gles
            st.subheader("üìã Tableau des R√®gles")
            display_df = filtered_rules[['support', 'confidence', 'lift']].copy()
            display_df['antecedents'] = filtered_rules['antecedents'].astype(str)
            display_df['consequents'] = filtered_rules['consequents'].astype(str)
            display_df = display_df[['antecedents', 'consequents', 'support', 'confidence', 'lift']]
            st.dataframe(display_df, use_container_width=True)
            
        else:
            st.warning("‚ö†Ô∏è Aucune r√®gle ne correspond aux crit√®res s√©lectionn√©s. Essayez de r√©duire les seuils.")
    else:
        st.info("‚ÑπÔ∏è Aucune r√®gle d'association trouv√©e.")
        st.markdown("""
        **Causes possibles :**
        - Les r√®gles n'ont pas √©t√© g√©n√©r√©es lors de l'entra√Ænement
        - Les donn√©es ne contiennent pas suffisamment de patterns
        - Les seuils de support/confiance sont trop √©lev√©s
        
        **Solutions :**
        1. V√©rifiez que mlxtend est install√©: `pip install mlxtend`
        2. R√©ex√©cutez le script d'entra√Ænement avec g√©n√©ration des r√®gles
        3. Utilisez le bouton ci-dessous pour g√©n√©rer les r√®gles maintenant
        """)
        
        if df is not None and st.button("üîÑ G√©n√©rer les r√®gles d'association maintenant"):
            with st.spinner("G√©n√©ration en cours..."):
                rules = generate_association_rules_from_data(df)
                if not rules.empty:
                    st.success("‚úÖ R√®gles g√©n√©r√©es avec succ√®s!")
                    st.rerun()
                else:
                    st.error("‚ùå Impossible de g√©n√©rer les r√®gles d'association")

def main():
    st.markdown('<h1 class="main-header">üéì Syst√®me de Pr√©vention de l\'Abandon Scolaire</h1>', unsafe_allow_html=True)
    
    # Chargement des donn√©es et mod√®les
    df, df_clustered = load_data()
    model_data, clustering_data = load_models()
    
    if df is None or model_data is None:
        st.stop()

    st.sidebar.title("üß≠ Navigation")
    page = st.sidebar.selectbox("Choisir une section:",
                                ["üìä Analyse Exploratoire", "üéØ Analyse des Clusters",
                                 "üîÆ Pr√©diction Individuelle", "üîó R√®gles d'Association"])

    if page == "üìä Analyse Exploratoire":
        show_exploratory_analysis(df, df_clustered)
    elif page == "üéØ Analyse des Clusters":
        show_clustering_analysis(df_clustered, clustering_data)
    elif page == "üîÆ Pr√©diction Individuelle":
        show_prediction_interface(model_data, clustering_data)
    elif page == "üîó R√®gles d'Association":
        show_association_rules(clustering_data, df)

    st.sidebar.markdown("---")
    st.sidebar.markdown("### üìà Statistiques du Mod√®le")
    if df is not None:
        st.sidebar.metric("Total √âtudiants", len(df))
        st.sidebar.metric("Taux d'Abandon", f"{(df['dropout'] == 'Yes').mean():.1%}")
    st.sidebar.markdown("---")
    st.sidebar.markdown("*D√©velopp√© avec ‚ù§Ô∏è par Gnabana S√©verin PIDJAKARE*")
    st.sidebar.markdown("*Email : gpidjakare@gmail.com*")
    st.sidebar.markdown("*Tel : +22870356451*")

if __name__ == "__main__":
    main()